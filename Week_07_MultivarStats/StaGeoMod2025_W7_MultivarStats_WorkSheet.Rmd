---
title: "Ordination and Classification of Vegetation Types"
subtitle: "Predicting Deciduous Broadleaf Forests using Climate Data"
author: "Student Name: Laura Ryge Koch"
date: "`r format(Sys.Date(), '%d %B %Y')`"
output:
  html_document:
    self_contained: yes
    number_sections: true
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, error = TRUE)
library(vegan)
library(tidyverse)

```

## Introduction

In this 90-minute practical, you will gain hands-on experience with multivariate ordination and classification techniques commonly used in ecology and biogeography. These methods help us understand how environmental variables structure biological communities and predict vegetation distributions.

### Learning Objectives:

- Apply Principal Component Analysis (PCA) to reduce dimensionality of environmental data
- Perform Principal Coordinates Analysis (PCoA) and Non-metric Multidimensional Scaling (NMDS)
- Use K-means clustering to classify vegetation types
- Interpret ordination plots and assess classification accuracy
- Predict the distribution of deciduous broadleaf forests based on climate variables

### Dataset Overview:

You have three datasets:

1. `BiomeData.csv` - Site locations (x, y coordinates) and biome classifications (500 sites per vegetation type)
2. `ClimateData.csv` - 19 bioclimatic variables plus elevation for each site
3. `WorldClimateData.csv` - Global climate data for prediction (not used in this practical)

The bioclimatic variables (bio.1 to bio.19) represent annual trends, seasonality, and extreme environmental factors derived from temperature and precipitation data.

### Bioclimatic Variables Reference Table

| Variable | Name | Description | Units |
|----------|------|-------------|-------|
| bio.1 | Annual Mean Temperature | Mean of all weekly mean temperatures | °C |
| bio.2 | Mean Diurnal Range | Mean of monthly (max temp - min temp) | °C |
| bio.3 | Isothermality | (bio.2/bio.7) × 100 | % |
| bio.4 | Temperature Seasonality | Standard deviation of weekly mean temperatures | °C × 100 |
| bio.5 | Max Temperature of Warmest Month | Highest temperature of any monthly maximum | °C |
| bio.6 | Min Temperature of Coldest Month | Lowest temperature of any monthly minimum | °C |
| bio.7 | Temperature Annual Range | bio.5 - bio.6 | °C |
| bio.8 | Mean Temperature of Wettest Quarter | Mean temperature during wettest quarter | °C |
| bio.9 | Mean Temperature of Driest Quarter | Mean temperature during driest quarter | °C |
| bio.10 | Mean Temperature of Warmest Quarter | Mean temperature during warmest quarter | °C |
| bio.11 | Mean Temperature of Coldest Quarter | Mean temperature during coldest quarter | °C |
| bio.12 | Annual Precipitation | Sum of monthly precipitation values | mm |
| bio.13 | Precipitation of Wettest Month | Precipitation of the wettest month | mm |
| bio.14 | Precipitation of Driest Month | Precipitation of the driest month | mm |
| bio.15 | Precipitation Seasonality | Coefficient of variation | % |
| bio.16 | Precipitation of Wettest Quarter | Total precipitation during wettest quarter | mm |
| bio.17 | Precipitation of Driest Quarter | Total precipitation during driest quarter | mm |
| bio.18 | Precipitation of Warmest Quarter | Total precipitation during warmest quarter | mm |
| bio.19 | Precipitation of Coldest Quarter | Total precipitation during coldest quarter | mm |

**Note:** Temperature variables are in degrees Celsius (°C), precipitation variables are in millimeters (mm). Quarter refers to a period of 3 consecutive months.

---

## Task 1: Principal Component Analysis (PCA)

### Background and Objectives

**What is PCA?**

Principal Component Analysis is an ordination technique that transforms correlated environmental variables into a smaller set of uncorrelated variables called principal components (PCs). Each PC is a linear combination of the original variables and captures a decreasing amount of variance in the dataset.

**Why use PCA?**

- Reduces dimensionality while retaining most variation in the data
- Identifies which environmental variables drive differences between sites
- Visualizes multidimensional data in 2D or 3D space
- Works best with linear relationships between variables

**What we will do:**

1. Load and prepare the climate and biome data
2. Standardize environmental variables
3. Perform PCA on the environmental data
4. Determine how many PC axes to retain
5. Interpret variable loadings
6. Visualize the ordination space colored by biome type
7. Add convex hulls

---

### Step 1.1: Load and Prepare Data

**What this step does:**
Import two CSV files containing biome classifications and climate data, merge them by their common ID column, extract the environmental variables, and check for missing values.

**Why we do this:**
We need to combine our ecological classification data with environmental predictors. Checking for missing values is essential because most statistical methods cannot handle missing data.

**Your task:** Write code to load the two CSV files, merge them, extract the 20 environmental variables (bio.1 through bio.19 plus Elev), and check for missing values.


```{r}
# Load the data

# HINT: stringsAsFactors keeps text as characters, [,-1] removes first column
biome <- read.csv("BiomeData.csv", 
                  stringsAsFactors = TRUE)[,-1]  # Remove column 1

# Read climate dataset
clim  <- read.csv("ClimateData.csv", 
                  stringsAsFactors = TRUE)[,-1]

# Merge datasets by ID

dat <- merge(biome, clim, by = "ID", all.x = T)
str(dat)

# Extract environmental variables (bio.1 to Elev)s

env_var <- dat[,c(5:24)]

# Check for and remove missing values

sum(is.na(env_var))  # Counts total NAs - no NAs, but if there was:
colSums(is.na(env_var))  # Counts NAs per column

# Remove rows with any missing values - there was none, but I'll still put the code
env_var <- na.omit(env_var)

str(env_var)

```


---

### Step 1.2: Perform PCA

**What this step does:**
Perform Principal Component Analysis using `prcomp()` with `scale. = TRUE` to standardize variables, then calculate variance explained by each component.

**Why we do this:**
Scaling is critical because bioclimatic variables have very different units and scales (temperature in °C vs precipitation in mm). Without scaling, variables with larger ranges would dominate the PCA.

**Your task:** Run PCA on the scaled environmental data and create a table showing variance explained by the first 10 PCs.


```{r}

# Perform PCA with scaling

PCA <- prcomp(env_var, scale. = TRUE)

# View summary of PCA
summary(PCA)

# Calculate variance explained

# Calculate variance explained by each principal component
variance <- PCA$sdev^2
variance_explained <- variance / sum(variance)
variance_explained_percent <- round(variance_explained*100, 3)

# Print variance explained (as proportions)
variance_explained_percent


# Create variance table
variance_table <- data.frame(
  PC = paste0("PC", 1:length(variance)),
  Variance = round(variance, 3),
  Proportion = round(variance_explained_percent, 3),
  Cumulative = round(cumsum(variance_explained), 3)
)

# View the table
knitr::kable(variance_table) # make it look prettyyy


```


---

### Step 1.3: Determine Number of Axes to Retain

**What this step does:**
Use two methods to decide how many principal components to keep: (1) Scree plot (elbow method), and (2) Broken stick model.

**Why we do this:**
Not all PCs are equally informative. These methods help us balance simplification with information retention.

**Elbow Method:** Look for the "elbow" where variance explained drops off
**Broken Stick Model:** Keep components explaining more variance than expected by chance

**Your task:** Create scree plots and calculate the number of PCs exceeding the broken stick threshold.

```{r}
# Scree plot

screeplot(PCA, bstick = TRUE, type="lines")
#or
plot(PCA, type="lines",main="Scree Plot")

# Broken stick model function

broken_stick <- function(n) {
  k <- 1:n
  expected <- sapply(k, function(i) sum(1 / k[i:n]) / n)
  return(expected)
}

# Compare observed vs expected

## i basically already did this, but here's another way to do it just for fun because this is so fun wuuhuuu
n_pcs <- length(variance_explained_percent)
expected_variance <- round(broken_stick(n_pcs)*100, 3)

plot(variance_explained_percent, type = "b", pch = 19,
     xlab = "Principal Component",
     ylab = "Proportion of Variance Explained (%)",
     main = "Broken Stick Model Comparison",
     ylim = c(0, max(variance_explained_percent, expected_variance)))
lines(expected_variance, type = "b", col = "red", lty = 2)
legend("topright",
       legend = c("Observed", "Broken Stick"),
       col = c("black", "red"),
       lty = c(1, 2),
       bty = "n")

# Count axes to retain

pcs_to_keep <- sum(variance_explained_percent > expected_variance)
pcs_to_keep # 3

```


---

### Step 1.4: Interpret Variable Loadings

**What this step does:**
Extract loadings for the first 3 PCs and identify the top 5 contributing variables for each.

**Why we do this:**
Loadings transform abstract mathematical axes into ecologically meaningful environmental gradients (e.g., "PC1 represents a temperature gradient").

**Your task:** Extract and interpret the loadings for PC1, PC2, and PC3.

```{r}

# Extract loadings (eigenvectors)
loadings <- PCA$rotation

# Identify top variables for each PC
# Function to get those bitches
top_contributors <- function(pc, n = 5) {
  abs_loadings <- abs(loadings[, pc])
  top_vars <- sort(abs_loadings, decreasing = TRUE)[1:n]
  data.frame(
    Variable = names(top_vars),
    Loading = loadings[names(top_vars), pc]
  )
}

# Top 5 variables for PC1, PC2, and PC3
top_PC1 <- top_contributors("PC1")
top_PC2 <- top_contributors("PC2")
top_PC3 <- top_contributors("PC3")

# Print the results
top_PC1
top_PC2
top_PC3


```


---

### Step 1.5: Visualize PCA Ordination

**What this step does:**
Plot sites in PCA space, colored by biome type, showing PC1 vs PC2, PC1 vs PC3, and PC2 vs PC3.

**Why we do this:**
Visualization reveals whether sites from the same biome cluster together (distinct environmental niches) or mix (overlapping tolerances).

**Your task:** Create ordination plots with biome colors and variance explained in axis labels.


```{r}


# easy way

biplot(PCA, choices = 1:2)
biplot(PCA, choices = c(1, 3))
biplot(PCA, choices = 2:3)

# Extract PC scores
scores <- as.data.frame(PCA$x)

# Add biome information
scores$Biome <- dat$BIOME.Name 



# Create color palette
biomes <- unique(scores$Biome)
colors <- rainbow(length(biomes))
names(colors) <- biomes

Biome_Types <- dat[complete.cases(dat),]

# Plot PC1 vs PC2, PC1 vs PC3, PC2 vs PC3

# PC1 vs PC2
plot(scores$PC1, scores$PC2,
     col = colors[scores$Biome],
     pch = 19,
     xlab = paste0("PC1 (", variance_explained_percent[1], "%)"),
     ylab = paste0("PC2 (", variance_explained_percent[2], "%)"),
     main = "PCA Ordination: PC1 vs PC2")
legend("topright",
       legend = unique(Biome_Types$BIOME.Name),
       col = colors,
       pch=19,
       cex=0.5,
       bg=NA)

# PC1 vs PC3
plot(scores$PC1, scores$PC3,
     col = colors[scores$Biome],
     pch = 19,
     xlab = paste0("PC1 (", variance_explained_percent[1], "%)"),
     ylab = paste0("PC3 (", variance_explained_percent[3], "%)"),
     main = "PCA Ordination: PC1 vs PC3")
legend("topright",
       legend = unique(Biome_Types$BIOME.Name),
       col = colors,
       pch=19,
       cex=0.5,
       bg=NA)

# PC2 vs PC3
plot(scores$PC2, scores$PC3,
     col = colors[scores$Biome],
     pch = 19,
     xlab = paste0("PC2 (", variance_explained_percent[1], "%)"),
     ylab = paste0("PC3 (", variance_explained_percent[3], "%)"),
     main = "PCA Ordination: PC2 vs PC3")
legend("topright",
       legend = unique(Biome_Types$BIOME.Name),
       col = colors,
       pch=19,
       cex=0.5,
       bg=NA)

```


---

### Step 1.6: Add Convex Hulls

**What this step does:**
Draw polygons enclosing all points belonging to each biome.

**Why we do this:**
Convex hulls visualize: (1) total environmental space occupied by each biome, (2) biome overlap in environmental conditions, and (3) environmental distinctiveness.

**Your task:** Add convex hulls to your PCA plots.

```{r}
# Function to add convex hulls
BiomeUse <- unique(Biome_Types$BIOME.Name[1])

for (BiomeUse in unique(Biome_Types$BIOME.Name)) {
  PositionsUse <- (scores[c(Biome_Types$BIOME.Name==BiomeUse), c("PC1", "PC2")])
  hull.edg <- chull(PositionsUse)
  polygon(PositionsUse[hull.edg,], border=1)
}


# Plot with hulls

# PC1 vs PC2
plot(scores$PC1, scores$PC2,
     col = colors[scores$Biome],
     pch = 19,
     xlab = paste0("PC1 (", variance_explained_percent[1], "%)"),
     ylab = paste0("PC2 (", variance_explained_percent[2], "%)"),
     main = "PCA Ordination: PC1 vs PC2")
legend("topright",
       legend = unique(Biome_Types$BIOME.Name),
       col = colors,
       pch=19,
       cex=0.5,
       bg=NA)
for (BiomeUse in unique(Biome_Types$BIOME.Name)) {
  PositionsUse <- (scores[c(Biome_Types$BIOME.Name==BiomeUse), c("PC1", "PC2")])
  hull.edg <- chull(PositionsUse)
  polygon(PositionsUse[hull.edg,], border=1)
}



# get the chat to do it for all three ordinations

# Define function to plot PCA ordination with convex hulls ----
plot_pca_hulls <- function(scores, biomes, colors, x_pc, y_pc, variance_explained_percent) {
  # Axis labels
  xlab <- paste0(x_pc, " (", round(variance_explained_percent[as.numeric(sub("PC", "", x_pc))], 1), "%)")
  ylab <- paste0(y_pc, " (", round(variance_explained_percent[as.numeric(sub("PC", "", y_pc))], 1), "%)")
  
  # Plot points
  plot(scores[[x_pc]], scores[[y_pc]],
       col = colors[scores$Biome],
       pch = 19,
       xlab = xlab,
       ylab = ylab,
       main = paste("PCA Ordination:", x_pc, "vs", y_pc))
  
  # Add convex hulls for each biome
  for (b in unique(biomes)) {
    pts <- scores[scores$Biome == b, c(x_pc, y_pc)]
    if (nrow(pts) > 2) {
      hull <- chull(pts)
      hull <- c(hull, hull[1])
      polygon(pts[hull, ], border = colors[b], lwd = 2)
    }
  }
  
  # Add legend
  legend("topright",
         legend = unique(biomes),
         col = colors,
         pch = 19,
         cex = 0.7,
         bty = "n")
}

# -----------------------------------------
# Run for all three ordinations ----

# Make sure scores$Biome exists
scores$Biome <- Biome_Types$BIOME.Name

# PC1 vs PC2
plot_pca_hulls(scores, unique(Biome_Types$BIOME.Name), colors,
               "PC1", "PC2", variance_explained_percent)

# PC1 vs PC3
plot_pca_hulls(scores, unique(Biome_Types$BIOME.Name), colors,
               "PC1", "PC3", variance_explained_percent)

# PC2 vs PC3
plot_pca_hulls(scores, unique(Biome_Types$BIOME.Name), colors,
               "PC2", "PC3", variance_explained_percent)


```



---

### Reflection Questions - Task 1

**Question 1.1:** Based on the scree plot and broken stick model, how many principal components would you retain for further analysis? Explain your reasoning and discuss what percentage of the total variance is explained by these components.

*3, because that's what the comparison of observed vs expected variance showed. they explain 80% of the variance together which is quite a lot*

**Question 1.2:** Examine the variable loadings for the first two principal components. What environmental gradients do PC1 and PC2 appear to represent? Which bioclimatic variables contribute most strongly to each axis, and what does this tell you about the main environmental factors differentiating these biomes?

*PC1 seems to represent a temperature gradient. It’s driven by variables of mean and minimum temperatures (bio1, bio6, bio11, bio9), it separates cold from warm biomes. PC2 represents a precepitaiton gradient. It’s mostly only influenced by precipitation variables (bio12, bio14, bio17, bio19) and temperature range (bio2), separating dry from wet environments. so the PC1 and PC2 together describe the main climatic differences between biomes - temperature and precipitation.*

---

## Task 2: Principal Coordinates Analysis (PCoA)

### Background and Objectives

**What is PCoA?**

Principal Coordinates Analysis (metric multidimensional scaling) works with distance matrices rather than raw data. Unlike PCA, PCoA can handle non-linear relationships through the choice of dissimilarity measure.

**Why use Euclidean distance?**

Euclidean distance is appropriate for continuous environmental data. When used with scaled variables, it produces results similar to PCA but demonstrates the distance-based framework.

**What we will do:**

1. Scale environmental variables
2. Calculate Euclidean distance matrix
3. Perform PCoA on the distance matrix
4. Determine how many PCo axes to retain
5. Visualize the ordination
6. Add convex hulls

---

### Step 2.1: Scale Environmental Data

**What this step does:**
Standardize each environmental variable to mean = 0 and standard deviation = 1 using `scale()`.

**Why we do this:**
Scaling ensures all variables contribute equally to distance calculations based on ecological variation, not measurement units.

**Your task:** Scale the environmental data and verify the transformation.

```r
# Scale environmental variables


# Verify scaling (check means and SDs)


```

---

### Step 2.2: Calculate Euclidean Distance

**What this step does:**
Calculate Euclidean distance between every pair of sites using `dist()`.

**Why we do this:**
The distance matrix quantifies environmental similarity. Sites with small distances have similar conditions; large distances indicate different conditions.

**Your task:** Calculate the Euclidean distance matrix and examine its properties.

```r
# Calculate distance matrix


# Display summary statistics


```

---

### Step 2.3: Perform PCoA

**What this step does:**
Use `cmdscale()` to perform PCoA, requesting 20 dimensions and eigenvalues, then calculate variance explained.

**Why we do this:**
PCoA transforms distances into an ordination space for visualization. With Euclidean distance on scaled data, PCoA is mathematically equivalent to PCA.

**Your task:** Perform PCoA and create a variance table for the first 10 axes.

```r
# Perform PCoA


# Calculate variance explained by positive eigenvalues


# Create variance table


```

---

### Step 2.4: Determine Number of Axes to Retain

**What this step does:**
Use scree plot and broken stick model to determine how many PCoA axes to retain.

**Why we do this:**
Focus on meaningful axes representing major environmental gradients rather than noise.

**Your task:** Create diagnostic plots and count axes exceeding the broken stick threshold.

```r
# Scree plot


# Broken stick comparison


# Count axes to retain


```

---

### Step 2.5: Visualize PCoA Ordination

**What this step does:**
Plot sites in PCoA space, colored by biome, showing PCo1 vs PCo2, PCo1 vs PCo3, and PCo2 vs PCo3.

**Why we do this:**
Assess whether sites from the same biome cluster together in environmental space.

**Your task:** Create PCoA ordination plots with biome colors.

```r
# Extract PCo scores


# Plot PCo1 vs PCo2, PCo1 vs PCo3, PCo2 vs PCo3


```

---

### Step 2.6: Add Convex Hulls to PCoA

**What this step does:**
Draw convex hulls around each biome in PCoA space.

**Why we do this:**
Compare environmental space occupied by biomes. Since we used Euclidean distance on scaled data, hulls should closely resemble PCA hulls.

**Your task:** Add convex hulls to PCoA plots.

```r
# Plot with convex hulls


```

---

### Reflection Questions - Task 2

**Question 2.1:** Compare the PCoA ordination to the PCA ordination. Since we used Euclidean distance on scaled data, the results should be mathematically equivalent (though possibly reflected or rotated). Do you observe this equivalence? What does this tell you about the relationship between PCA and distance-based ordination methods?

**Question 2.2:** Looking at the convex hulls in the PCoA plots, which biomes show the most overlap in environmental space? Which are most distinct? What might this tell you about the environmental specificity of different vegetation types?

---

## Task 3: Non-metric Multidimensional Scaling (NMDS)

### Background and Objectives

**What is NMDS?**

Non-metric Multidimensional Scaling uses rank orders rather than absolute distances, making it robust to non-linear relationships.

**Understanding Stress:**

Stress measures goodness-of-fit:
- Stress < 0.05: Excellent
- Stress < 0.10: Good
- Stress < 0.20: Acceptable
- Stress > 0.20: Poor (use more dimensions)

**What we will do:**

1. Load the vegan package
2. Perform NMDS with different numbers of dimensions
3. Plot stress vs dimensionality
4. Select optimal dimensions
5. Visualize the ordination
6. Add convex hulls

---

### Step 3.1: Run NMDS with Different Dimensions

**What this step does:**
Run NMDS using 2, 3, 4, and 5 dimensions with `metaMDS()`, performing multiple random starts for each.

**Why we do this:**
Test different dimensionalities to find the optimal balance between simplicity and fit quality. Multiple random starts avoid local optima.

**Your task:** Run NMDS for k = 2, 3, 4, 5 and record stress values.

```r
# Load vegan package


# Run NMDS for different dimensions


```

---

### Step 3.2: Plot Stress vs Number of Dimensions

**What this step does:**
Create a stress plot with reference lines at 0.05, 0.10, and 0.20.

**Why we do this:**
Identify minimum dimensions needed for acceptable fit, balancing stress reduction with interpretability.

**Your task:** Create stress plot and identify optimal dimensionality.

```r
# Plot stress vs dimensions


# Add reference lines


# Identify optimal dimensions


```

---

### Step 3.3: Visualize NMDS Ordination

**What this step does:**
Plot NMDS axes 1 vs 2, 1 vs 3, and 2 vs 3, colored by biome.

**Why we do this:**
Assess whether NMDS successfully separates biomes based on environmental similarity.

**Important differences from PCA/PCoA:**
- No variance explained (all axes equally important)
- Arbitrary rotation (only relative positions matter)
- Rank-based (robust to non-linear relationships)

**Your task:** Create NMDS ordination plots.

```r
# Extract NMDS scores


# Plot NMDS1 vs NMDS2, NMDS1 vs NMDS3, NMDS2 vs NMDS3


```

---

### Step 3.4: Add Convex Hulls to NMDS

**What this step does:**
Draw convex hulls around each biome in NMDS space.

**Why we do this:**
Compare biome separation across all three ordination methods to understand which captures biome-climate relationships best.

**Your task:** Add convex hulls to NMDS plots and compare with PCA and PCoA results.

```r
# Plot with convex hulls


```

---

### Reflection Questions - Task 3

**Question 3.1:** Based on the stress values you calculated, which number of dimensions provides the best balance between model complexity and goodness-of-fit? Would you consider the representation with your chosen number of dimensions to be excellent, good, or acceptable according to standard stress guidelines?

**Question 3.2:** Compare the three ordination methods (PCA, PCoA, and NMDS) in terms of how clearly they separate the different biomes. Which method appears most effective for distinguishing vegetation types? Why might different ordination techniques produce different patterns?

---

## Task 4: Non-hierarchical Classification (K-means Clustering)

### Background and Objectives

**What is K-means clustering?**

K-means partitions objects into k clusters by minimizing within-cluster variation through iterative assignment and centroid recalculation.

**Why use ordination spaces?**

Ordination reduces noise and collinearity, producing more interpretable and stable clusters than the original high-dimensional space.

**What we will do:**

1. Apply K-means to PCA, PCoA, and NMDS spaces
2. Compare classifications across methods
3. Determine optimal number of clusters
4. Assess classification accuracy

---

### Step 4.1: K-means on All Three Ordination Spaces

**What this step does:**
Apply K-means clustering to PCA, PCoA, and NMDS spaces using k = number of known biomes.

**Why we do this:**
Compare which ordination technique best captures natural groupings in climate-vegetation data.

**Key outputs:**
- Total within-cluster SS (lower = more compact clusters)
- Between-cluster SS (higher = more separated clusters)
- Ratio (higher = better-defined clusters)

**Your task:** Run K-means on all three ordination spaces and compare results.

```r
# K-means on PCA space


# K-means on PCoA space


# K-means on NMDS space


# Compare results


```

---

### Step 4.2: Visualize K-means Classifications

**What this step does:**
Create side-by-side plots showing original biomes vs K-means clusters for each ordination method.

**Why we do this:**
Visually assess how well unsupervised clustering recovers known biome patterns.

**Your task:** Create comparison plots with cluster centroids marked.

```r
# Plot original biomes vs K-means clusters for PCA


# Repeat for PCoA


# Repeat for NMDS


```

---

### Step 4.3: Determine Optimal Number of Clusters

**What this step does:**
Test k = 2 to 15 using: (1) Elbow method (within-cluster SS), and (2) Silhouette method (cluster quality).

**Why we do this:**
The true number of ecological groups may differ from named biomes. Find the number best fitting data structure.

**Your task:** Create elbow and silhouette plots, identify optimal k.

```r
# Test k = 2:15


# Plot elbow method


# Plot silhouette scores


# Identify optimal k


```

---

### Step 4.4: Run K-means with Optimal Clusters

**What this step does:**
Perform K-means with optimal k and create confusion matrix comparing clusters to actual biomes.

**Why we do this:**
Compare data-driven clustering with expert-defined biome system.

**Your task:** Run optimal K-means and examine confusion matrix.

```r
# K-means with optimal k


# Visualize


# Create confusion matrix


```

---

### Step 4.5: Assess Classification Accuracy

**What this step does:**
Calculate accuracy for each clustering method by matching clusters to biomes.

**Why we do this:**
Quantify agreement between unsupervised clustering and expert-defined biomes.

**Your task:** Calculate and compare accuracies across all methods.

```r
# Function to calculate accuracy


# Calculate accuracies for all methods


# Display results


```

---

### Reflection Questions - Task 4

**Question 4.1:** Compare the classification accuracies across the three ordination methods (PCA, PCoA, NMDS). Which ordination space produced the most accurate K-means clustering? Why might certain ordination methods be more suitable for classification tasks than others?

**Question 4.2:** You determined an optimal number of clusters using the silhouette method, which may differ from the actual number of biomes in the dataset. What does this suggest about the natural structure of vegetation types based on climate data? Discuss whether biomes are truly discrete categories or whether they represent points along continuous environmental gradients.

---

## Summary and Conclusions

### Key Findings

Today you have learned to:

1. **Apply ordination techniques** - PCA, PCoA, and NMDS each reveal different aspects of environmental structure
2. **Determine dimensionality** - Using scree plots, broken stick models, and stress values
3. **Classify ecological data** - K-means clustering identifies natural groupings
4. **Validate classifications** - Accuracy metrics assess whether groups are meaningful

### Take-Home Messages

- **No single best method**: Different techniques have different strengths
- **Dimensionality matters**: Balance information retention with simplification
- **Classification is challenging**: Ecosystems exist along continua, not in discrete boxes
- **Statistical validation is essential**: Always test significance and evaluate accuracy

### Further Exploration

Consider these extensions:

- Predict vegetation types at unsampled locations
- Apply hierarchical clustering and compare to K-means
- Identify key variables discriminating specific biome types
- Explore machine learning approaches for classification